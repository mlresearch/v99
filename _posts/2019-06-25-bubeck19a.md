---
abstract: We propose a near-optimal method for highly smooth convex optimization. More precisely, in the oracle model where one obtains the $p^{th}$ order Taylor expansion of a function at the query point, we propose a method with rate of convergence $\tilde{O}(1/k^{\frac{ 3p +1}{2}})$ after $k$ queries to the oracle for any convex function whose $p^{th}$ order derivative is Lipschitz.
section: contributed
title: Near-optimal method for highly smooth convex optimization
layout: inproceedings
series: Proceedings of Machine Learning Research
id: bubeck19a
month: 0
tex_title: Near-optimal method for highly smooth convex optimization
firstpage: 492
lastpage: 507
page: 492-507
order: 492
cycles: false
bibtex_author: Bubeck, S{\'e}bastien and Jiang, Qijia and Lee, Yin Tat and Li, Yuanzhi and Sidford, Aaron
author:
- given: SÃ©bastien
  family: Bubeck
- given: Qijia
  family: Jiang
- given: Yin Tat
  family: Lee
- given: Yuanzhi
  family: Li
- given: Aaron
  family: Sidford
date: 2019-06-25
address: 
publisher: PMLR
container-title: Proceedings of the Thirty-Second Conference on Learning Theory
volume: '99'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 6
  - 25
pdf: http://proceedings.mlr.press/v99/bubeck19a/bubeck19a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
